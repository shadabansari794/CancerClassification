{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11695054,"sourceType":"datasetVersion","datasetId":7340344}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T19:03:56.972230Z","iopub.execute_input":"2025-05-06T19:03:56.972531Z","iopub.status.idle":"2025-05-06T19:03:57.266654Z","shell.execute_reply.started":"2025-05-06T19:03:56.972499Z","shell.execute_reply":"2025-05-06T19:03:57.265846Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/cancerfinetuning/val.csv\n/kaggle/input/cancerfinetuning/train.csv\n/kaggle/input/cancerfinetuning/test.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"pip install transformers accelerate peft datasets bitsandbytes trl\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T19:03:57.267960Z","iopub.execute_input":"2025-05-06T19:03:57.268293Z","iopub.status.idle":"2025-05-06T19:05:28.956495Z","shell.execute_reply.started":"2025-05-06T19:03:57.268275Z","shell.execute_reply":"2025-05-06T19:05:28.955316Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.3.0)\nRequirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\nCollecting trl\n  Downloading trl-0.17.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.5.1+cu124)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.16)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl) (14.0.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (2.19.1)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading trl-0.17.0-py3-none-any.whl (348 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m348.0/348.0 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, trl, bitsandbytes\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bitsandbytes-0.45.5 fsspec-2024.12.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 trl-0.17.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"config = {\n  \"base_model\": \"bert-base-uncased\",\n  \"lora_r\": 8,\n  \"lora_alpha\": 16,\n  \"lora_dropout\": 0.05,\n  \"max_length\": 512,\n  \"train_batch_size\": 4,\n  \"eval_batch_size\": 4,\n  \"learning_rate\": 2e-5,\n  \"num_train_epochs\": 3,\n  \"output_dir\": \"/kaggle/working/lora_bert-base-uncased\"\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T19:05:28.957782Z","iopub.execute_input":"2025-05-06T19:05:28.958087Z","iopub.status.idle":"2025-05-06T19:05:28.962355Z","shell.execute_reply.started":"2025-05-06T19:05:28.958057Z","shell.execute_reply":"2025-05-06T19:05:28.961696Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport torch.nn.functional as F  # ✅ this line is critical\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nfrom peft import get_peft_model, LoraConfig, TaskType\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix\nfrom tqdm import tqdm\nimport json\nimport openpyxl\nfrom openpyxl.utils.dataframe import dataframe_to_rows\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T19:31:59.135457Z","iopub.execute_input":"2025-05-06T19:31:59.135811Z","iopub.status.idle":"2025-05-06T19:31:59.816080Z","shell.execute_reply.started":"2025-05-06T19:31:59.135791Z","shell.execute_reply":"2025-05-06T19:31:59.815515Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"train_df = load_data(\"/kaggle/input/cancerfinetuning/train.csv\")\nval_df = load_data(\"/kaggle/input/cancerfinetuning/val.csv\")\ntest_df =load_data(\"/kaggle/input/cancerfinetuning/test.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T19:22:08.084707Z","iopub.execute_input":"2025-05-06T19:22:08.085199Z","iopub.status.idle":"2025-05-06T19:22:08.131838Z","shell.execute_reply.started":"2025-05-06T19:22:08.085179Z","shell.execute_reply":"2025-05-06T19:22:08.131058Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# ========== SETUP ==========\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel_name = \"bert-base-uncased\"\n\n# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\n# LoRA config\nlora_config = LoraConfig(\n    r=8,\n    lora_alpha=16,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=TaskType.SEQ_CLS\n)\n\n# Load model\nbase_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\nmodel = get_peft_model(base_model, lora_config).to(device)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T19:34:33.664393Z","iopub.execute_input":"2025-05-06T19:34:33.664743Z","iopub.status.idle":"2025-05-06T19:34:34.139371Z","shell.execute_reply.started":"2025-05-06T19:34:33.664721Z","shell.execute_reply":"2025-05-06T19:34:34.138535Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":" # Tokenization helper\ndef tokenize_data(df):\n    tokens = tokenizer(\n        list(df[\"abstract\"]),\n        padding=\"max_length\",\n        truncation=True,\n        max_length=512,\n        return_tensors=\"pt\"\n    )\n    tokens[\"labels\"] = torch.tensor(df[\"label\"].values, dtype=torch.long)\n    return TensorDataset(tokens['input_ids'], tokens['attention_mask'], tokens['labels'])\n\n# Dataset loaders\n\ntrain_loader = DataLoader(tokenize_data(train_df), batch_size=8, shuffle=True)\nval_loader = DataLoader(tokenize_data(val_df), batch_size=8, shuffle=True)\ntest_loader = DataLoader(tokenize_data(test_df), batch_size=8, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T19:34:48.533624Z","iopub.execute_input":"2025-05-06T19:34:48.533907Z","iopub.status.idle":"2025-05-06T19:34:49.237407Z","shell.execute_reply.started":"2025-05-06T19:34:48.533885Z","shell.execute_reply":"2025-05-06T19:34:49.236828Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)  # ⬅️ Increase from 2e-5\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T19:44:18.967680Z","iopub.execute_input":"2025-05-06T19:44:18.968967Z","iopub.status.idle":"2025-05-06T19:44:18.975543Z","shell.execute_reply.started":"2025-05-06T19:44:18.968924Z","shell.execute_reply":"2025-05-06T19:44:18.974832Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"# ========== TRAIN + VAL ==========\nmodel.train()\nfor epoch in range(5):\n    total_train_loss = 0\n\n    # TRAIN\n    model.train()\n    for batch in tqdm(train_loader, desc=f\"[Train] Epoch {epoch+1}\"):\n        input_ids, attention_mask, labels = [x.to(device) for x in batch]\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        total_train_loss += loss.item()\n\n    avg_train_loss = total_train_loss / len(train_loader)\n\n    # VALIDATION\n    model.eval()\n    total_val_loss = 0\n    with torch.no_grad():\n        for batch in val_loader:\n            input_ids, attention_mask, labels = [x.to(device) for x in batch]\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n            val_loss = outputs.loss\n            total_val_loss += val_loss.item()\n\n    avg_val_loss = total_val_loss / len(val_loader)\n\n    print(f\"📘 Epoch {epoch+1} - Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T19:44:20.833792Z","iopub.execute_input":"2025-05-06T19:44:20.834595Z","iopub.status.idle":"2025-05-06T19:48:59.028908Z","shell.execute_reply.started":"2025-05-06T19:44:20.834562Z","shell.execute_reply":"2025-05-06T19:48:59.028137Z"}},"outputs":[{"name":"stderr","text":"[Train] Epoch 1: 100%|██████████| 75/75 [00:49<00:00,  1.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"📘 Epoch 1 - Train Loss: 0.7047 | Val Loss: 0.6923\n","output_type":"stream"},{"name":"stderr","text":"[Train] Epoch 2: 100%|██████████| 75/75 [00:48<00:00,  1.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"📘 Epoch 2 - Train Loss: 0.6999 | Val Loss: 0.6837\n","output_type":"stream"},{"name":"stderr","text":"[Train] Epoch 3: 100%|██████████| 75/75 [00:48<00:00,  1.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"📘 Epoch 3 - Train Loss: 0.6853 | Val Loss: 0.6671\n","output_type":"stream"},{"name":"stderr","text":"[Train] Epoch 4: 100%|██████████| 75/75 [00:48<00:00,  1.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"📘 Epoch 4 - Train Loss: 0.6131 | Val Loss: 0.4313\n","output_type":"stream"},{"name":"stderr","text":"[Train] Epoch 5: 100%|██████████| 75/75 [00:48<00:00,  1.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"📘 Epoch 5 - Train Loss: 0.2830 | Val Loss: 0.1922\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"# ========== EVALUATION ==========\nlabel_map_rev = {0: \"Non-Cancer\", 1: \"Cancer\"}\nresults = []\nsummary = []\nconfusion_blocks = {}\n\ndef evaluate_and_collect(name, df, loader):\n    model.eval()\n    all_preds, all_probs, all_labels = [], [], []\n    with torch.no_grad():\n        for batch in loader:\n            input_ids, attention_mask, labels = [x.to(device) for x in batch]\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n            probs = F.softmax(outputs.logits, dim=1)\n            preds = torch.argmax(probs, dim=1)\n\n            all_preds.extend(preds.cpu().numpy())\n            all_probs.extend(probs.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    # Metrics\n    acc = accuracy_score(all_labels, all_preds)\n    f1 = f1_score(all_labels, all_preds)\n    cm = confusion_matrix(all_labels, all_preds)\n    print(f\"✅ {name} Accuracy: {acc:.2%} | F1: {f1:.2f}\")\n\n    summary.append({\n        \"Split\": name,\n        \"Accuracy\": f\"{acc:.2%}\",\n        \"F1-score\": f\"{f1:.2f}\"\n    })\n\n    # Confusion matrix block\n    cm_df = pd.DataFrame(cm, index=[\"Actual Cancer\", \"Actual Non-Cancer\"],\n                         columns=[\"Predicted Cancer\", \"Predicted Non-Cancer\"])\n    confusion_blocks[name] = cm_df\n\n    # Predictions JSON style\n    for i, row in df.iterrows():\n        results.append({\n            \"id\": str(row['id']),\n            \"split\": name,\n            \"true_label\": label_map_rev[row['label']],\n            \"predicted_label\": label_map_rev[all_preds[i]],\n            \"confidence_scores\": {\n                \"Cancer\": round(float(all_probs[i][1]), 3),\n                \"Non-Cancer\": round(float(all_probs[i][0]), 3)\n            }\n        })\n\n# Evaluate all 3 splits\nevaluate_and_collect(\"train\", train_df.reset_index(drop=True), train_loader)\nevaluate_and_collect(\"val\", val_df.reset_index(drop=True), val_loader)\nevaluate_and_collect(\"test\", test_df.reset_index(drop=True), test_loader)\n\n# ========== EXPORT RESULTS ==========\n# Save predictions\nwith open(\"/kaggle/working/bert_lora_all_predictions.json\", \"w\") as f:\n    json.dump(results, f, indent=2)\n\n# Save metrics & confusion matrices to Excel\nexcel_path = \"/kaggle/working/bert_lora_report.xlsx\"\nwb = openpyxl.Workbook()\nws_summary = wb.active\nws_summary.title = \"Metrics\"\nfor r in dataframe_to_rows(pd.DataFrame(summary), index=False, header=True):\n    ws_summary.append(r)\n\nws_cm = wb.create_sheet(\"Confusion_Matrix\")\nfor name, df in confusion_blocks.items():\n    ws_cm.append([name])  # Add title\n    for r in dataframe_to_rows(df, index=True, header=True):\n        ws_cm.append(r)\n    ws_cm.append([])\n\nwb.save(excel_path)\nprint(f\"📄 Saved all results to: {excel_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T19:51:33.017600Z","iopub.execute_input":"2025-05-06T19:51:33.018363Z","iopub.status.idle":"2025-05-06T19:52:07.863069Z","shell.execute_reply.started":"2025-05-06T19:51:33.018339Z","shell.execute_reply":"2025-05-06T19:52:07.862428Z"}},"outputs":[{"name":"stdout","text":"✅ train Accuracy: 96.17% | F1: 0.96\n✅ val Accuracy: 95.00% | F1: 0.95\n✅ test Accuracy: 95.00% | F1: 0.95\n📄 Saved all results to: /kaggle/working/bert_lora_report.xlsx\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}